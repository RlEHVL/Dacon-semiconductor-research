# 반도체 연구 (공모전)
> 이미 늦음... 쩝...

![image](https://github.com/user-attachments/assets/9596f2d7-d648-46e2-804f-478eda6f7549)

![image](https://github.com/user-attachments/assets/185cc738-1a9c-4c67-9b23-dcb5479aadb3)
이 이미지는 데이터의 각 변수에 대한 **박스플롯(Boxplot)**을 보여줍니다. 박스플롯은 변수의 분포, 중앙값, 사분위수 및 이상치를 시각적으로 표현하는 데 유용합니다. 각 변수의 특징과 이상치를 분석하며 해석해보겠습니다.

---

## **1. 박스플롯 구조**
박스플롯에서 주목해야 할 부분:
- **중앙값(Median)**:
  - 박스 내부의 선으로 표시되며, 데이터의 중앙값을 나타냅니다.
- **사분위수(IQR, Interquartile Range)**:
  - 박스의 상단과 하단은 각각 **3사분위수(Q3)**와 **1사분위수(Q1)**를 나타냅니다.
  - IQR = Q3 - Q1
- **Whisker(수염)**:
  - 박스 위아래로 뻗은 선으로, 데이터를 1.5 × IQR 내에서 표시합니다.
  - Whisker 밖의 점들은 **이상치(Outliers)**로 간주됩니다.

---

## **2. 각 변수의 해석**
### **(1) x_0, x_1, x_2, x_3, x_7, x_9, x_8**
- 분포:
  - 이 변수들은 비교적 **정상적인 분포**를 가지고 있으며, 중앙값이 박스의 중간에 위치.
  - 이상치가 거의 없거나 발견되지 않음.
- 해석:
  - 해당 변수들은 데이터의 변동성이 적으며, 대부분의 값이 IQR 범위 안에 포함됨.
  - 학습 모델에 안정적으로 기여할 가능성이 높음.

### **(2) x_4**
- 분포:
  - **중앙값이 박스 하단에 가까움**, 데이터가 약간 왼쪽으로 치우친(Skewed) 분포를 가질 가능성이 있음.
  - Whisker 하단에 다수의 **이상치**가 존재.
- 해석:
  - 이상치가 많이 발견되며, 해당 변수는 특정 극단적인 상황에서 중요한 정보를 나타낼 수 있음.
  - 모델 학습 전에 이상치를 처리(예: 클리핑, 제거)하거나, 로그 변환을 고려할 수 있음.

### **(3) x_5**
- 분포:
  - 중앙값이 비교적 중앙에 위치하나, Whisker 하단에 다수의 **이상치** 존재.
- 해석:
  - x_4와 비슷한 특성을 가지며, 이상치가 결과에 영향을 미칠 가능성이 있음.
  - 이상치 처리 또는 상관관계를 고려한 추가 분석 필요.

### **(4) x_6**
- 분포:
  - Whisker 상단에 다수의 **이상치** 존재.
- 해석:
  - 데이터가 오른쪽으로 약간 치우친(Skewed) 분포를 가질 가능성이 있음.
  - 이상치가 변수의 중요성을 왜곡할 수 있으므로, 처리 필요.

### **(5) x_10**
- 분포:
  - Whisker 하단에 소수의 **이상치**가 존재.
- 해석:
  - 이상치가 비교적 적으며, 대부분의 데이터는 IQR 범위에 포함됨.
  - 해당 변수는 안정적으로 학습 모델에 기여할 가능성이 있음.

---

1. **이상치 제거**:
   - IQR을 기준으로 Whisker 밖의 이상치를 제거.
   - 단, 이상치가 데이터의 중요한 특성을 나타낼 수 있으므로 신중히 처리.
2. **클리핑(값 제한)**:
   - 이상치를 상/하한값(Q1 - 1.5 × IQR, Q3 + 1.5 × IQR)으로 조정.
3. **변환(예: 로그 변환)**:
   - x_4, x_5처럼 이상치가 많은 변수에 로그 변환을 적용하여 분포를 정규화.
4. **모델 기반 처리**:
   - 모델이 이상치를 자연스럽게 학습하도록, 별도의 처리 없이 그대로 유지.

---\
1. **"이 박스플롯은 데이터 변수들의 분포와 이상치를 시각적으로 보여줍니다."**
2. **"대부분의 변수는 정상적인 분포를 가지며, 이상치가 적습니다. 그러나 x_4, x_5, x_6 변수에서는 다수의 이상치가 발견되었습니다."**

---

추가적으로 이상치 처리 후 모델 성능에 미친 영향을 함께 제시하면 더 설득력 있는 설명이 될 것입니다. 필요하면 추가로 도와드리겠습니다! 😊

![image](https://github.com/user-attachments/assets/923aa327-38f0-4639-9cb2-7b745b35a6db)

주어진 상관관계 히트맵은 테스트 데이터(`test.csv`)의 각 변수 간 상관관계를 나타냅니다. 상관계수의 값은 -1에서 1 사이의 범위를 가지며, 다음과 같이 해석할 수 있습니다:

---

## **상관관계 해석**
1. **상관계수의 의미**:
   - **양의 상관관계 (+)**: 한 변수가 증가하면 다른 변수도 증가하는 경향이 있음.
   - **음의 상관관계 (-)**: 한 변수가 증가하면 다른 변수는 감소하는 경향이 있음.
   - **상관관계 없음 (0에 가까움)**: 두 변수 간에 선형적인 관계가 거의 없음.

2. **상관계수의 강도**:
   - **0.7 이상 또는 -0.7 이하**: 강한 상관관계.
   - **0.3 ~ 0.7 또는 -0.3 ~ -0.7**: 중간 정도의 상관관계.
   - **0.3 미만 또는 -0.3 초과**: 약한 상관관계.

---

## **히트맵의 주요 해석**
1. **강한 상관관계**:
   - `x_1`과 `x_7`의 상관관계: **0.97** (양의 강한 상관관계).
   - `x_4`와 `x_5`의 상관관계: **-0.98** (음의 강한 상관관계).
   - `x_10`과 `x_5`의 상관관계: **-0.99** (음의 강한 상관관계).

   - **의미**: 
     - `x_1`과 `x_7`은 서로 매우 유사한 패턴을 가지며, 둘 중 하나만 사용하거나 파생 변수(곱)를 생성할 수 있음.
     - `x_4`와 `x_5` 또는 `x_10`과 `x_5`는 음의 강한 상관관계가 있으므로, 모델이 둘의 영향을 상쇄하거나 의존하지 않도록 주의해야 함.

2. **중간 정도의 상관관계**:
   - `x_0`과 `x_3`: **-0.65** (음의 중간 상관관계).
   - `x_2`와 `x_10`: **0.68** (양의 중간 상관관계).

   - **의미**:
     - 중간 정도의 상관관계를 가지는 변수는 개별적으로 의미 있는 정보일 가능성이 있으므로 주의 깊게 다룰 필요가 있음.

3. **약한 상관관계 또는 상관 없음**:
   - `x_2`와 `x_6`: **-0.26** (약한 음의 상관관계).
   - `x_6`과 `x_7`: **0.48** (약한 양의 상관관계).

   - **의미**:
     - 약한 상관관계를 가진 변수는 독립적으로 작용할 가능성이 있으므로, 분석과 모델링에서 중요한 역할을 할 수 있음.

---

![image](https://github.com/user-attachments/assets/3d1edc3b-ee30-41cb-82a3-9faad1e77b31)

![image](https://github.com/user-attachments/assets/563eeac8-0ceb-418b-b121-a27f4bd0fe10)
> [Val] DNN Recall: 0.8905
> Model Weights based on Recall: RF=0.25, XGB=0.25, LGBM=0.25, DNN=0.25
> [Val] Ensemble Recall: 0.8955


이 그래프는 **딥러닝 모델(DNN)의 학습과 검증 손실(loss) 변화**를 보여줍니다. 이 그래프를 해석하기 위해 상위 퍼센트 예측값과의 관계를 정리하면 다음과 같습니다.

---

## **그래프 해석**
### **1. Train Loss (왼쪽)**:
- **파란 선**은 학습 데이터에서의 손실(오차) 감소를 나타냅니다.
- 학습 초기에는 손실 값이 매우 크지만, Epoch가 진행됨에 따라 급격히 감소한 후 안정화.
- **해석**:
  - 모델이 학습 데이터를 점점 잘 예측하게 되었음을 의미합니다.

### **2. Validation Loss (오른쪽)**:
- **주황 선**은 검증 데이터에서의 손실(오차) 감소를 나타냅니다.
- 초기에는 손실이 크지만 빠르게 감소한 후, 안정적인 값을 유지.
- **해석**:
  - 모델이 검증 데이터에서도 과적합 없이 적절하게 학습했음을 의미합니다.

### **결론**:
- Train Loss와 Validation Loss 모두 안정적으로 수렴했으며, 두 값이 비슷한 수준으로 유지되고 있습니다.
- 이는 모델이 학습 데이터에 과적합하지 않고 일반화 성능을 유지하고 있음을 시사합니다.

---

1. **그래프의 의미**:
   - "이 그래프는 딥러닝 모델의 학습 및 검증 손실 변화를 보여줍니다. 손실 값이 안정적으로 감소하고 검증 데이터에서도 낮은 손실 값을 유지하고 있어 모델의 일반화 성능이 우수함을 확인할 수 있습니다."

2. **상위 퍼센트와의 연결**:
   - "이 그래프는 모델의 전체 성능을 나타내며, 상위 10% 예측값의 Recall 성능도 이러한 안정적인 학습 결과에서 비롯됩니다."
   - "구체적인 상위 퍼센트 Recall은 별도의 계산을 통해 검증되었으며, 이를 통해 최적의 결과를 도출했습니다."

---

