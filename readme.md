# 반도체 연구 (공모전)
> 이미 늦음... 쩝...

![image](https://github.com/user-attachments/assets/9596f2d7-d648-46e2-804f-478eda6f7549)

![image](https://github.com/user-attachments/assets/185cc738-1a9c-4c67-9b23-dcb5479aadb3)

![image](https://github.com/user-attachments/assets/923aa327-38f0-4639-9cb2-7b745b35a6db)

주어진 상관관계 히트맵은 테스트 데이터(`test.csv`)의 각 변수 간 상관관계를 나타냅니다. 상관계수의 값은 -1에서 1 사이의 범위를 가지며, 다음과 같이 해석할 수 있습니다:

---

## **상관관계 해석**
1. **상관계수의 의미**:
   - **양의 상관관계 (+)**: 한 변수가 증가하면 다른 변수도 증가하는 경향이 있음.
   - **음의 상관관계 (-)**: 한 변수가 증가하면 다른 변수는 감소하는 경향이 있음.
   - **상관관계 없음 (0에 가까움)**: 두 변수 간에 선형적인 관계가 거의 없음.

2. **상관계수의 강도**:
   - **0.7 이상 또는 -0.7 이하**: 강한 상관관계.
   - **0.3 ~ 0.7 또는 -0.3 ~ -0.7**: 중간 정도의 상관관계.
   - **0.3 미만 또는 -0.3 초과**: 약한 상관관계.

---

## **히트맵의 주요 해석**
1. **강한 상관관계**:
   - `x_1`과 `x_7`의 상관관계: **0.97** (양의 강한 상관관계).
   - `x_4`와 `x_5`의 상관관계: **-0.98** (음의 강한 상관관계).
   - `x_10`과 `x_5`의 상관관계: **-0.99** (음의 강한 상관관계).

   - **의미**: 
     - `x_1`과 `x_7`은 서로 매우 유사한 패턴을 가지며, 둘 중 하나만 사용하거나 파생 변수(곱)를 생성할 수 있음.
     - `x_4`와 `x_5` 또는 `x_10`과 `x_5`는 음의 강한 상관관계가 있으므로, 모델이 둘의 영향을 상쇄하거나 의존하지 않도록 주의해야 함.

2. **중간 정도의 상관관계**:
   - `x_0`과 `x_3`: **-0.65** (음의 중간 상관관계).
   - `x_2`와 `x_10`: **0.68** (양의 중간 상관관계).

   - **의미**:
     - 중간 정도의 상관관계를 가지는 변수는 개별적으로 의미 있는 정보일 가능성이 있으므로 주의 깊게 다룰 필요가 있음.

3. **약한 상관관계 또는 상관 없음**:
   - `x_2`와 `x_6`: **-0.26** (약한 음의 상관관계).
   - `x_6`과 `x_7`: **0.48** (약한 양의 상관관계).

   - **의미**:
     - 약한 상관관계를 가진 변수는 독립적으로 작용할 가능성이 있으므로, 분석과 모델링에서 중요한 역할을 할 수 있음.

---

![image](https://github.com/user-attachments/assets/3d1edc3b-ee30-41cb-82a3-9faad1e77b31)

![image](https://github.com/user-attachments/assets/563eeac8-0ceb-418b-b121-a27f4bd0fe10)
> [Val] DNN Recall: 0.8905
> Model Weights based on Recall: RF=0.25, XGB=0.25, LGBM=0.25, DNN=0.25
> [Val] Ensemble Recall: 0.8955


이 그래프는 **딥러닝 모델(DNN)의 학습과 검증 손실(loss) 변화**를 보여줍니다. 이 그래프를 해석하기 위해 상위 퍼센트 예측값과의 관계를 정리하면 다음과 같습니다.

---

## **그래프 해석**
### **1. Train Loss (왼쪽)**:
- **파란 선**은 학습 데이터에서의 손실(오차) 감소를 나타냅니다.
- 학습 초기에는 손실 값이 매우 크지만, Epoch가 진행됨에 따라 급격히 감소한 후 안정화.
- **해석**:
  - 모델이 학습 데이터를 점점 잘 예측하게 되었음을 의미합니다.

### **2. Validation Loss (오른쪽)**:
- **주황 선**은 검증 데이터에서의 손실(오차) 감소를 나타냅니다.
- 초기에는 손실이 크지만 빠르게 감소한 후, 안정적인 값을 유지.
- **해석**:
  - 모델이 검증 데이터에서도 과적합 없이 적절하게 학습했음을 의미합니다.

### **결론**:
- Train Loss와 Validation Loss 모두 안정적으로 수렴했으며, 두 값이 비슷한 수준으로 유지되고 있습니다.
- 이는 모델이 학습 데이터에 과적합하지 않고 일반화 성능을 유지하고 있음을 시사합니다.

---

1. **그래프의 의미**:
   - "이 그래프는 딥러닝 모델의 학습 및 검증 손실 변화를 보여줍니다. 손실 값이 안정적으로 감소하고 검증 데이터에서도 낮은 손실 값을 유지하고 있어 모델의 일반화 성능이 우수함을 확인할 수 있습니다."

2. **상위 퍼센트와의 연결**:
   - "이 그래프는 모델의 전체 성능을 나타내며, 상위 10% 예측값의 Recall 성능도 이러한 안정적인 학습 결과에서 비롯됩니다."
   - "구체적인 상위 퍼센트 Recall은 별도의 계산을 통해 검증되었으며, 이를 통해 최적의 결과를 도출했습니다."

---

